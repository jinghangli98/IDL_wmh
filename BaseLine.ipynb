{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be95ba50-5f0f-411b-a258-acaf30001682",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imageio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnibabel\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnib\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimageio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mim\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imageio'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchsummaryX import summary\n",
    "import torch \n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import imageio.v2 as im\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "from torchvision import transforms, utils\n",
    "import pdb\n",
    "import datetime\n",
    "from torchmetrics import JaccardIndex\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from ResUnet7TFLAIR import *\n",
    "import tqdm\n",
    "import gc\n",
    "from natsort import natsorted\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d918d5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nibabel\n",
      "  Downloading nibabel-4.0.2-py3-none-any.whl (3.3 MB)\n",
      "     ---------------------------------------- 3.3/3.3 MB 15.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=17.0 in d:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from nibabel) (21.3)\n",
      "Requirement already satisfied: setuptools in d:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from nibabel) (57.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lerry lee\\appdata\\roaming\\python\\python39\\site-packages (from nibabel) (1.23.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from packaging>=17.0->nibabel) (3.0.9)\n",
      "Installing collected packages: nibabel\n",
      "Successfully installed nibabel-4.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b87ca3f-0f43-43d2-9458-8ad19fe614c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = 1.0\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        assert y_pred.size() == y_true.size()\n",
    "        y_pred = y_pred[:, 0].contiguous().view(-1)\n",
    "        y_true = y_true[:, 0].contiguous().view(-1)\n",
    "        intersection = (y_pred * y_true).sum()\n",
    "        dsc = (2. * intersection + self.smooth) / (\n",
    "            y_pred.sum() + y_true.sum() + self.smooth\n",
    "        )\n",
    "        return 1. - dsc\n",
    "\n",
    "def readImage(path,subjN):\n",
    "    img_array = []\n",
    "    img_dir = []\n",
    "    affine_array = []\n",
    "    counter = 0\n",
    "    for directory_path in path:\n",
    "        img_dir.append(directory_path)\n",
    "    img_dir.sort()\n",
    "\n",
    "    for path_i in img_dir:\n",
    "        img = nib.load(path_i).get_fdata()\n",
    "        img = img/np.max(img)\n",
    "        affine = nib.load(path_i).affine\n",
    "        img_array.append(img)\n",
    "        affine_array.append(affine)\n",
    "        counter += 1\n",
    "        if counter >= subjN: break\n",
    "\n",
    "    img_array = np.array(img_array,dtype=object)\n",
    "    affine_array = np.array(affine_array,dtype=object)\n",
    "    print(path_i)\n",
    "    return img_array, affine_array\n",
    " \n",
    "def sliceImage(image, output_size):\n",
    "    image_stack = []\n",
    "    new_h, new_w, new_z = output_size\n",
    "    normalization=transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    for img in image:\n",
    "        h, w, z = np.shape(img)\n",
    "        if h < new_h:\n",
    "            pad_size = int((new_h - h)/2)\n",
    "            img = np.pad(img, ((pad_size, pad_size), (0,0), (0,0)))\n",
    "        elif h > new_h:\n",
    "            crop_size = int((h - new_h)/2)\n",
    "            img = img[crop_size:h-crop_size, :, :]\n",
    "        if w < new_w:\n",
    "            pad_size = int((new_w - w)/2)\n",
    "            img = np.pad(img, ((0,0), (pad_size, pad_size), (0,0)))\n",
    "        elif w > new_w:\n",
    "            crop_size = int((w - new_w)/2)\n",
    "            img = img[:, crop_size:w-crop_size, :]\n",
    "        pad_size = int(new_z/2)\n",
    "        img = np.pad(img, ((0,0), (0,0), (pad_size, pad_size)))\n",
    "        for z in range(np.shape(img)[2]):\n",
    "            img_z = np.rot90(img[:,:,z:z+new_z])\n",
    "            #img_z = np.expand_dims(img_z, 0)\n",
    "            image_stack.append(img_z)\n",
    "    return np.array(image_stack)\n",
    "\n",
    "def load_train_val(train, val, size, num):\n",
    "    img_train = glob.glob(train['img'])\n",
    "    mask_train = glob.glob(train['mask'])\n",
    "    len_train_mask=len(mask_train)\n",
    "    \n",
    "    \n",
    "    img_test = glob.glob(val['img'])\n",
    "    mask_test = glob.glob(val['mask'])\n",
    "    len_test_mask=len(mask_test)\n",
    "    \n",
    "    img_train = natsorted(img_train)\n",
    "    mask_train = natsorted(mask_train)\n",
    "    #img_train=img_train[-len_train_mask:]\n",
    "    \n",
    "    img_test = natsorted(img_test)\n",
    "    mask_test = natsorted(mask_test)\n",
    "    \n",
    "    #img_test = img_test[-len_train_mask:]\n",
    "    FLAIR_train, FLAIR_train_affine = readImage(img_train, num)\n",
    "    FLAIR_train_mask, _ = readImage(mask_train, num)\n",
    "    FLAIR_train_stack = sliceImage(FLAIR_train, size).astype('float')\n",
    "    mask_train_stack = sliceImage(FLAIR_train_mask, size).astype('float')\n",
    "    \n",
    "    \n",
    "    FLAIR_test, FLAIR_test_affine = readImage(img_test, 5)\n",
    "    FLAIR_test_mask, _ = readImage(mask_test, 5)\n",
    "    FLAIR_test_stack = sliceImage(FLAIR_test, size).astype('float')\n",
    "    mask_test_stack = sliceImage(FLAIR_test_mask, size).astype('float')\n",
    "    \n",
    "    flair_trainset = TensorDataset(torch.tensor(FLAIR_train_stack), torch.tensor(mask_train_stack))\n",
    "    flair_testset = TensorDataset(torch.tensor(FLAIR_test_stack), torch.tensor(mask_test_stack))\n",
    "    \n",
    "    return flair_trainset, flair_testset\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df6e6cdf-1e11-4d5e-a8cd-2bea5b03b38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size': 64, # Increase this if your GPU can handle it\n",
    "    'lr': 0.0001,\n",
    "    'epochs': 100, # 10 epochs is recommended ONLY for the early submission - you will have to train for much longer typically.\n",
    "    # Include other parameters as needed.\n",
    "}\n",
    "\n",
    "criterion = DiceLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.8, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b92bf13-3ce7-454d-aa0c-688f4a6b879d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/ocean/projects/cis220078p/zli11/MRIPublic/public/dataset/102/orig/FLAIR_mask.nii.gz',\n",
       " '/ocean/projects/cis220078p/zli11/MRIPublic/public/dataset/112/orig/FLAIR_mask.nii.gz',\n",
       " '/ocean/projects/cis220078p/zli11/MRIPublic/public/dataset/132/orig/FLAIR_mask.nii.gz']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natsorted(glob.glob('/ocean/projects/cis220078p/zli11/MRIPublic/public/dataset/*2/orig/FLAIR_mask.nii.gz'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a984510a-71c8-4791-8e6b-24e0c174a782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 256, 83)\n",
      "(132, 256, 83)\n",
      "(132, 256, 83)\n"
     ]
    }
   ],
   "source": [
    "path_list=natsorted(glob.glob('/ocean/projects/cis220078p/zli11/MRIPublic/public/dataset/*2/orig/FLAIR_mask.nii.gz'))\n",
    "for path in path_list:\n",
    "    print(nib.load(path).get_fdata().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0c40b68-698f-492b-b3b7-b23cebdcc542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ocean/projects/cis220078p/zli11/MRIPublic/public/AMS/144/orig/FLAIR.nii.gz\n",
      "/ocean/projects/cis220078p/zli11/MRIPublic/public/AMS/144/orig/FLAIR_mask.nii.gz\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "At least one stride in the given numpy array is negative, and tensors with negative strides are not currently supported. (You can probably work around this by making a copy of your array  with array.copy().) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40169/2248959672.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m        'mask': '/ocean/projects/cis220078p/zli11/MRIPublic/public/AMS/*2/orig/FLAIR_mask.nii.gz'}\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mflair_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflair_testset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_train_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflair_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflair_testset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_40169/1904221251.py\u001b[0m in \u001b[0;36mload_train_val\u001b[0;34m(train, val, size, num)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mFLAIR_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFLAIR_train_affine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mFLAIR_train_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mFLAIR_train_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msliceImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAIR_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0mmask_train_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msliceImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAIR_train_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_40169/1904221251.py\u001b[0m in \u001b[0;36msliceImage\u001b[0;34m(image, output_size)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mimg_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrot90\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mimg_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mnormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_z\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mimage_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_z\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: At least one stride in the given numpy array is negative, and tensors with negative strides are not currently supported. (You can probably work around this by making a copy of your array  with array.copy().) "
     ]
    }
   ],
   "source": [
    "train = {'img': '/ocean/projects/cis220078p/zli11/MRIPublic/public/AMS/*/orig/FLAIR.nii.gz', \n",
    "        'mask': '/ocean/projects/cis220078p/zli11/MRIPublic/public/AMS/*/orig/FLAIR_mask.nii.gz'}\n",
    "\n",
    "test = {'img': '/ocean/projects/cis220078p/zli11/MRIPublic/public/AMS/*2/orig/FLAIR.nii.gz',\n",
    "       'mask': '/ocean/projects/cis220078p/zli11/MRIPublic/public/AMS/*2/orig/FLAIR_mask.nii.gz'}\n",
    "\n",
    "flair_trainset, flair_testset = load_train_val(train, test, [256, 256], 60)\n",
    "train_loader = DataLoader(flair_trainset, batch_size = 32, shuffle=True)\n",
    "test_loader = DataLoader(flair_testset, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a25003-de8d-489b-88ba-ad0f65740af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    IOU = 0\n",
    "    batch_bar = tqdm.tqdm(total=len(dataloader), dynamic_ncols=True, leave=False, position=0, desc='Train', ncols=5)\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images.float())\n",
    "        loss = criterion(outputs, labels.float())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        jaccard = JaccardIndex('multiclass',num_classes=2).to(device)\n",
    "        acc = jaccard(outputs, labels.int())\n",
    "        \n",
    "        acc = torch.Tensor.cpu(acc)\n",
    "        IOU += acc\n",
    "        \n",
    "        batch_bar.set_postfix(\n",
    "            acc='{:.04f}%'.format(100*IOU/(i+1)),\n",
    "            loss='{:.04f}'.format(float(running_loss)/(i+1)),\n",
    "            lr='{:.04f}'.format(float(optimizer.param_groups[0]['lr'])))\n",
    "        batch_bar.update()\n",
    "    batch_bar.close()\n",
    "\n",
    "    epoch_acc = IOU/len(dataloader)\n",
    "    epoch_loss = float(running_loss/len(dataloader))\n",
    "    \n",
    "\n",
    "    return epoch_acc * 100, epoch_loss\n",
    "\n",
    "def validate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    batch_bar = tqdm.tqdm(total=len(dataloader), dynamic_ncols=True, position=0, leave=False, desc='Val', ncols=5)\n",
    "\n",
    "    IOU = 0.0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(dataloader):\n",
    "        \n",
    "        # Move images to device\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        \n",
    "        # Get model outputs\n",
    "        with torch.inference_mode():\n",
    "            outputs = model(images.float())\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        jaccard = JaccardIndex('multiclass',num_classes=2).to(device)\n",
    "        acc = jaccard(outputs, labels.int())\n",
    "        acc = torch.Tensor.cpu(acc)\n",
    "        IOU += acc\n",
    "        running_loss += float(loss.item())\n",
    "\n",
    "        batch_bar.set_postfix(\n",
    "            acc=\"{:.04f}%\".format(100 * IOU / (i + 1)),\n",
    "            loss=\"{:.04f}\".format(float(running_loss / (i + 1))))\n",
    "\n",
    "        batch_bar.update()\n",
    "        \n",
    "        if i % 9 == 0:\n",
    "            test_input = images[0,:,:,:].expand(1,-1, -1, -1) \n",
    "            test_output = model(test_input.float())\n",
    "            test_output = torch.Tensor.cpu(test_output)\n",
    "            test_output = test_output.detach().numpy()\n",
    "            test_input = torch.Tensor.cpu(test_input)\n",
    "            label_img = torch.Tensor.cpu(labels[0,:,:,:])\n",
    "            label_img = label_img.detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "            plt.figure(1)\n",
    "            f, axs = plt.subplots(2,2,figsize=(15,15))\n",
    "            plt.subplot(141)\n",
    "            plt.imshow(test_output[0,0,:,:], cmap = 'gray')\n",
    "            plt.subplot(142)\n",
    "            plt.imshow(test_input[0,0,:,:], cmap = 'gray')\n",
    "            plt.subplot(143)\n",
    "            plt.imshow(test_input[0,0,:,:], cmap = 'gray')\n",
    "            plt.imshow(test_output[0,0,:,:], cmap = 'gray', alpha = 0.5)\n",
    "            plt.subplot(144)\n",
    "            plt.imshow(test_input[0,0,:,:], cmap = 'gray')\n",
    "            plt.imshow(label_img[0,:,:], cmap = 'gray', alpha = 0.5)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "        \n",
    "    batch_bar.close()\n",
    "    \n",
    "    epoch_acc = IOU/len(dataloader)\n",
    "    epoch_loss = float(running_loss/len(dataloader))\n",
    "\n",
    "    return epoch_acc * 100, epoch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0740787-dd88-4d15-9de7-c8bad2fed662",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d393d7cc-651e-43ae-b8a6-1110eb9e9760",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valacc = 0.0\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    \n",
    "    # if epoch %49 == 0:\n",
    "    #     optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], betas=(0.9, 0.999), eps=1e-08)\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.8, patience=2)\n",
    "    #     curr_lr = float(optimizer.param_groups[0]['lr'])\n",
    "    #     print(f'Epoch: {epoch}, Learning rate: {curr_lr}')\n",
    "\n",
    "    epoch_train_acc, epoch_train_loss = train(model, epoch, train_loader, optimizer, criterion)\n",
    "    curr_lr = float(optimizer.param_groups[0]['lr'])\n",
    "    print(\"\\nEpoch {}/{}: \\nTrain Acc {:.04f}%\\t Train Loss {:.04f}\\t Learning Rate {:.04f}\".format(\n",
    "        epoch + 1,\n",
    "        config['epochs'],\n",
    "        epoch_train_acc,\n",
    "        epoch_train_loss,\n",
    "        curr_lr))\n",
    "    epoch_test_acc, epoch_test_loss = validate(model, test_loader, criterion)\n",
    "    scheduler.step(epoch_test_loss)\n",
    "    \n",
    "    print(\"Val Acc {:.04f}%\\t Val Loss {:.04f}\".format(epoch_test_acc, epoch_test_loss))\n",
    "\n",
    "    \n",
    "    if epoch_test_acc >= best_valacc:\n",
    "      #path = os.path.join(root, model_directory, 'checkpoint' + '.pth')\n",
    "        print(\"Saving model\")\n",
    "        torch.save({'model_state_dict':model.state_dict(),\n",
    "                  'optimizer_state_dict':optimizer.state_dict(),\n",
    "                  #'scheduler_state_dict':scheduler.state_dict(),\n",
    "                  'val_acc': epoch_test_acc, \n",
    "                  'epoch': epoch}, './7T_No_Norm.pth')\n",
    "        best_valacc = epoch_test_acc\n",
    "      # wandb.save('7T_no_Norm.pth')\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d34752b-1921-415d-88ef-6c3cc435b5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
